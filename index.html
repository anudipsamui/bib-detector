<script>
const video = document.getElementById('video');
const overlay = document.getElementById('overlay');
const ctx = overlay.getContext('2d');
const startBtn = document.getElementById('startBtn');

let stream;
let inferEngine;
let workerId;
let detectionInterval;

// Replace with your Roboflow publishable key
const MODEL_NAME = "bib-number-labeling";
const MODEL_VERSION = "2";
const PUBLISHABLE_KEY = "rf_3HHrpOkdE4arP6EJhtDqcxZMpyf1";

async function startDetection() {
    try {
        // Start camera
        stream = await navigator.mediaDevices.getUserMedia({ video:{ facingMode:"environment" } });
        video.srcObject = stream;
        video.style.display = "block";
        await video.play();

        // Setup canvas size
        overlay.width = video.videoWidth;
        overlay.height = video.videoHeight;

        // Initialize Roboflow Inference (global InferenceJS)
        inferEngine = new InferenceJS.InferenceEngine();
        workerId = await inferEngine.startWorker(MODEL_NAME, MODEL_VERSION, PUBLISHABLE_KEY);

        // Start inference loop
        detectionInterval = setInterval(processFrame, 1000);

        startBtn.disabled = true;
        startBtn.innerText = "Detecting...";
    } catch(err) {
        alert("Failed: " + err.message);
        console.error(err);
    }
}

async function processFrame() {
    if (!video.videoWidth) return;

    const cvimg = new InferenceJS.CVImage(video);
    const predictions = await inferEngine.infer(workerId, cvimg);

    ctx.clearRect(0,0,overlay.width, overlay.height);

    for (const p of predictions) {
        const { x, y, width, height } = p.bbox;
        ctx.strokeStyle = "red";
        ctx.lineWidth = 3;
        ctx.strokeRect(x, y, width, height);
        ctx.font = "18px Arial";
        ctx.fillStyle = "red";
        ctx.fillText(p.className + " " + Math.round(p.confidence*100) + "%", x, y-5);
    }
}

startBtn.addEventListener('click', startDetection);
</script>
